# -*- coding: utf-8 -*-


"""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë                                                                              ‚ïë
‚ïë  ‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ïó ‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ïó         ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ïó   ‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ïó   ‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ïë
‚ïë  ‚ñà‚ñà‚ïë ‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë        ‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ïë‚ïö‚ïê‚ïê‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù‚ïë
‚ïë  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù ‚ïö‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ïë        ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ñà‚ñà‚ïó ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë   ‚ïë
‚ïë  ‚ñà‚ñà‚ïî‚ïê‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë        ‚ñà‚ñà‚ïë‚ñÑ‚ñÑ ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë‚ïö‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë   ‚ïë
‚ïë  ‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïó ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó   ‚ïö‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ïö‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë ‚ïö‚ñà‚ñà‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë   ‚ïë
‚ïë  ‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïù ‚ïö‚ïê‚ïù‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïù‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù    ‚ïö‚ïê‚ïê‚ñÄ‚ñÄ‚ïê‚ïù  ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù ‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïù‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïê‚ïê‚ïù   ‚ïö‚ïê‚ïù   ‚ïë
‚ïë                                                                              ‚ïë
‚ïë ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚ïë
‚ïë                                                                              ‚ïë
‚ïë                 DEEPHEDGE PLAYMAKER ‚Äî COMPLETE INTEGRATED SYSTEM             ‚ïë
‚ïë                                                                              ‚ïë
‚ïë    Attention Mechanism ‚Ä¢ Exit Optimization ‚Ä¢ Risk Management ‚Ä¢ MT5 + Ably    ‚ïë
‚ïë    Thread-Safe Position Cache ‚Ä¢ Rate-Limited Execution ‚Ä¢ Discord Alerts      ‚ïë
‚ïë                                                                              ‚ïë
‚ïë ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚ïë
‚ïë                                                                              ‚ïë
‚ïë   ASSET:    Volatility 75 Index           ACTIONS:  BUY ‚Ä¢ SELL ‚Ä¢ HOLD        ‚ïë
‚ïë   MODEL:    AttentionEnhancedDeepHedge    VERSION:  v2.2-FINAL | 2025-12-24  ‚ïë
‚ïë   EXIT:     PortfolioExitOptimizer        HORIZON: 5                         ‚ïë
‚ïë                                                                              ‚ïë
‚ïë                                                                              ‚ïë          
‚ïë         "Attention-driven exits, market-validated rewards, production-ready" ‚ïë
‚ïë                                                                              ‚ïë
‚ïë                 [ SYSTEM ONLINE ] v2.2-FINAL | 2025-12-24                    ‚ïë
‚ïë                                                                              ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

@author: ENG Karl

"""


"""
DeepHedge PlayMaker v2.2-FINAL - FULLY INTEGRATED & DEBUGGED

CHANGELOG v2.2-FINAL:
- ‚úÖ Fixed minvola_output dict access
- ‚úÖ Fixed model forward call compatibility
- ‚úÖ Added thread-safe position cache with asyncio.Lock
- ‚úÖ Enhanced position data validation with type checking
- ‚úÖ Added rate limiting for close orders
- ‚úÖ Better error handling throughout
- ‚úÖ Consistent dict access patterns
"""
!pip install ably
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import asyncio
import logging
import json
import traceback
import math
from datetime import datetime, timezone
from collections import deque
from enum import Enum
from typing import Dict, List, Optional
import time
import sys

try:
    from ably import AblyRealtime
    ABLY_AVAILABLE = True
except ImportError:
    ABLY_AVAILABLE = False
    print("‚ö†Ô∏è  Ably not installed. Install: pip install ably")

# Configuration
FULL_ABLY_KEY = "utg-jQ.yZ_9Yg:JhJvxFWQdywPLQNDgYoa89aNEwh5g8XWgUs0EUN4mM0"
ABLY_SIGNAL_CHANNEL = "final_signals"
ABLY_PRICE_SPREAD_POSITIONINFO_CHANNEL = "feature_data"
ABLY_MT5_ORDERS_CHANNEL = "orders"
ABLY_KEY_NAME, ABLY_KEY_SECRET = FULL_ABLY_KEY.split(":")

ACTION_MAP = {0: 'BUY', 1: 'SELL', 2: 'HOLD'}
ACTION_REVERSE = {'BUY': 0, 'SELL': 1, 'HOLD': 2}

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(levelname)s | %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S',
    stream=sys.stdout,
    force=True
)
logger = logging.getLogger(__name__)


# ============================================================================
# PORTFOLIO EXIT OPTIMIZATION
# ============================================================================

class PortfolioStateMonitor:
    def __init__(self, lookback=100):
        self.lookback = lookback
        self.pnl_history = deque(maxlen=lookback)
        self.position_history = deque(maxlen=lookback)
        self.price_history = deque(maxlen=lookback)
        self.max_drawdown = 0.0
        self.current_drawdown = 0.0
        self.peak_portfolio_value = 10000.0
        
    def update(self, positions_data, market_data):
        if not positions_data:
            return {
                'total_pnl': 0.0, 'net_position': 0.0, 'portfolio_value': 10000.0,
                'current_drawdown': 0.0, 'max_drawdown': self.max_drawdown,
                'var_95': 0.0, 'cvar_95': 0.0, 'sharpe': 0.0, 'volatility': 0.0,
                'concentration': 0.0, 'num_positions': 0, 'avg_hold_time': 0.0,
                'pnl_velocity': 0.0
            }
        
        total_pnl = sum(p.get('profit', 0.0) for p in positions_data)
        net_position = sum(
            p.get('volume', 0.0) * (1 if p.get('type') == 'BUY' else -1) 
            for p in positions_data
        )
        portfolio_value = 10000.0 + total_pnl
        
        self.pnl_history.append(total_pnl)
        self.position_history.append(net_position)
        self.price_history.append(market_data.get('price', 1500.0))
        
        if portfolio_value > self.peak_portfolio_value:
            self.peak_portfolio_value = portfolio_value
        
        self.current_drawdown = (self.peak_portfolio_value - portfolio_value) / self.peak_portfolio_value
        self.max_drawdown = max(self.max_drawdown, self.current_drawdown)
        
        if len(self.pnl_history) >= 20:
            pnl_array = np.array(self.pnl_history)
            returns = np.diff(pnl_array) / (10000.0 + pnl_array[:-1])
            var_95 = np.percentile(returns, 5)
            cvar_95 = returns[returns <= var_95].mean() if any(returns <= var_95) else var_95
            sharpe = (returns.mean() / returns.std()) * np.sqrt(252 * 24 * 12) if returns.std() > 0 else 0
            volatility = returns.std() * np.sqrt(252 * 24 * 12)
        else:
            var_95 = cvar_95 = sharpe = volatility = 0.0
        
        volumes = np.array([abs(p.get('volume', 0.0)) for p in positions_data])
        total_volume = volumes.sum()
        concentration = ((volumes / total_volume) ** 2).sum() if total_volume > 0 else 0.0
        
        return {
            'total_pnl': total_pnl, 'net_position': net_position,
            'portfolio_value': portfolio_value, 'current_drawdown': self.current_drawdown,
            'max_drawdown': self.max_drawdown, 'var_95': var_95, 'cvar_95': cvar_95,
            'sharpe': sharpe, 'volatility': volatility, 'concentration': concentration,
            'num_positions': len(positions_data),
            'avg_hold_time': self._calculate_avg_hold_time(positions_data),
            'pnl_velocity': self._calculate_pnl_velocity()
        }
    
    def _calculate_avg_hold_time(self, positions_data):
        if not positions_data:
            return 0.0
        current_time = datetime.now(timezone.utc).timestamp()
        hold_times = [(current_time - p.get('time_open', current_time)) / 3600 for p in positions_data]
        return np.mean(hold_times) if hold_times else 0.0
    
    def _calculate_pnl_velocity(self):
        if len(self.pnl_history) < 10:
            return 0.0
        recent_pnls = list(self.pnl_history)[-10:]
        time_points = np.arange(len(recent_pnls))
        return float(np.polyfit(time_points, recent_pnls, 1)[0])


class ExitSignalGenerator:
    def __init__(self, risk_free_rate=0.01):
        self.risk_free_rate = risk_free_rate
        
    def compute_exit_score(self, position, portfolio_state, market_data, quantum_signal):
        risk_score = self._compute_risk_score(position, portfolio_state)
        return_score = self._compute_return_score(position, portfolio_state)
        time_score = self._compute_time_score(position)
        regime_score = self._compute_regime_score(market_data, quantum_signal)
        reversal_score = self._compute_reversal_score(position, quantum_signal)
        
        weights = {'risk': 0.30, 'return': 0.25, 'time': 0.15, 'regime': 0.15, 'reversal': 0.15}
        
        exit_score = (
            weights['risk'] * risk_score + weights['return'] * return_score +
            weights['time'] * time_score + weights['regime'] * regime_score +
            weights['reversal'] * reversal_score
        )
        
        return exit_score, {
            'risk_score': risk_score, 'return_score': return_score,
            'time_score': time_score, 'regime_score': regime_score,
            'reversal_score': reversal_score, 'exit_score': exit_score
        }
    
    def _compute_risk_score(self, position, portfolio_state):
        score = 0.0
        profit = position.get('profit', 0.0)
        volume = position.get('volume', 0.01)
        price_open = position.get('price_open', 1500.0)
        
        if profit < 0:
            loss_pct = abs(profit) / max(volume * price_open, 0.01)
            score += 1.0 / (1.0 + np.exp(-10 * (loss_pct - 0.02)))
        if portfolio_state['current_drawdown'] > 0.05:
            score += min(portfolio_state['current_drawdown'] / 0.10, 1.0)
        if portfolio_state['concentration'] > 0.5:
            score += 0.3
        return np.clip(score / 2.3, 0.0, 1.0)
    
    def _compute_return_score(self, position, portfolio_state):
        score = 0.0
        profit = position.get('profit', 0.0)
        volume = position.get('volume', 0.01)
        price_open = position.get('price_open', 1500.0)
        
        profit_pct = profit / max(volume * price_open, 0.01)
        if profit_pct > 0.03:
            score += min(profit_pct / 0.05, 1.0)
        if portfolio_state['pnl_velocity'] < 0:
            score += 0.3
        if portfolio_state['sharpe'] < 0.5:
            score += 0.2
        return np.clip(score, 0.0, 1.0)
    
    def _compute_time_score(self, position):
        current_time = datetime.now(timezone.utc).timestamp()
        time_open = position.get('time_open', current_time)
        hold_time_hours = (current_time - time_open) / 3600
        return 1.0 / (1.0 + np.exp(-0.1 * (hold_time_hours - 24)))
    
    def _compute_regime_score(self, market_data, quantum_signal):
        score = 0.0
        if market_data.get('realized_vol', 75.0) > 90.0:
            score += 0.5
        if quantum_signal.get('confidence', 0.5) < 0.3:
            score += 0.3
        return np.clip(score, 0.0, 1.0)
    
    def _compute_reversal_score(self, position, quantum_signal):
        position_direction = 1 if position.get('type') == 'BUY' else -1
        signal_direction = quantum_signal.get('direction', 0.0)
        if position_direction * signal_direction < -0.5:
            return quantum_signal.get('confidence', 0.0)
        return 0.0


class OptimalLiquidationEngine:
    def __init__(self, risk_aversion=1e-6, price_impact=0.1):
        self.risk_aversion = risk_aversion
        self.price_impact = price_impact
        
    def compute_immediate_exit_size(self, exit_score, position_size, max_exit_pct=0.5):
        if exit_score < 0.3:
            exit_pct = 0.0
        elif exit_score < 0.7:
            exit_pct = 0.10 + (exit_score - 0.3) * 0.5
        else:
            exit_pct = min(0.30 + (exit_score - 0.7) * 1.0, max_exit_pct)
        return position_size * exit_pct


class PortfolioExitOptimizer:
    def __init__(self, min_exit_size=0.01, max_exit_pct=0.5):
        self.state_monitor = PortfolioStateMonitor()
        self.signal_generator = ExitSignalGenerator()
        self.liquidation_engine = OptimalLiquidationEngine()
        self.min_exit_size = min_exit_size
        self.max_exit_pct = max_exit_pct
        self.exit_decisions = deque(maxlen=100)
        
        logger.info("‚úÖ PortfolioExitOptimizer initialized")
    
    def evaluate_exits(self, positions_data, market_data, quantum_signal):
        portfolio_state = self.state_monitor.update(positions_data, market_data)
        
        logger.info(f"üìä Portfolio: PnL=${portfolio_state['total_pnl']:.2f}, "
                   f"DD={portfolio_state['current_drawdown']:.1%}, "
                   f"Sharpe={portfolio_state['sharpe']:.2f}")
        
        exit_orders = []
        
        for position in positions_data:
            try:
                exit_score, components = self.signal_generator.compute_exit_score(
                    position, portfolio_state, market_data, quantum_signal
                )
                
                ticket = position.get('ticket', 'UNKNOWN')
                logger.info(f"   Position {ticket}: Exit={exit_score:.2f} "
                           f"[R={components['risk_score']:.2f}, Ret={components['return_score']:.2f}, "
                           f"T={components['time_score']:.2f}, Rev={components['reversal_score']:.2f}]")
                
                if exit_score > 0.5:
                    volume = position.get('volume', 0.0)
                    exit_size = self.liquidation_engine.compute_immediate_exit_size(
                        exit_score, volume, self.max_exit_pct
                    )
                    
                    if exit_size >= self.min_exit_size:
                        close_order = {
                            'action': 'CLOSE',
                            'ticket': ticket,
                            'volume': round(exit_size, 3),
                            'reason': self._generate_exit_reason(components),
                            'exit_score': exit_score
                        }
                        exit_orders.append(close_order)
                        logger.info(f"   üì§ Exit: Close {exit_size:.3f} lots | {close_order['reason']}")
            except Exception as e:
                logger.error(f"   ‚ùå Error evaluating position {position.get('ticket', 'UNKNOWN')}: {e}")
                continue
        
        return exit_orders
    
    def _generate_exit_reason(self, components):
        reasons = []
        if components['risk_score'] > 0.6:
            reasons.append("Risk")
        if components['return_score'] > 0.6:
            reasons.append("Profit")
        if components['time_score'] > 0.7:
            reasons.append("Time")
        if components['reversal_score'] > 0.6:
            reasons.append("Reversal")
        if components['regime_score'] > 0.6:
            reasons.append("Regime")
        return " | ".join(reasons) if reasons else "Optimal Exit"


# ============================================================================
# MULTI-HEAD ATTENTION (Stub classes for completeness)
# ============================================================================

class MultiHeadAttention(nn.Module):
    def __init__(self, d_model, num_heads, dropout=0.1):
        super().__init__()
        assert d_model % num_heads == 0
        self.d_model = d_model
        self.num_heads = num_heads
        self.d_k = d_model // num_heads
        self.W_q = nn.Linear(d_model, d_model)
        self.W_k = nn.Linear(d_model, d_model)
        self.W_v = nn.Linear(d_model, d_model)
        self.W_o = nn.Linear(d_model, d_model)
        self.dropout = nn.Dropout(dropout)
        self.scale = math.sqrt(self.d_k)
        
    def split_heads(self, x, batch_size):
        x = x.view(batch_size, -1, self.num_heads, self.d_k)
        return x.permute(0, 2, 1, 3)
    
    def forward(self, query, key, value, mask=None):
        batch_size = query.size(0)
        Q = self.split_heads(self.W_q(query), batch_size)
        K = self.split_heads(self.W_k(key), batch_size)
        V = self.split_heads(self.W_v(value), batch_size)
        
        scores = torch.matmul(Q, K.transpose(-2, -1)) / self.scale
        if mask is not None:
            scores = scores.masked_fill(mask == 0, -1e9)
        
        attention_weights = self.dropout(torch.softmax(scores, dim=-1))
        context = torch.matmul(attention_weights, V)
        context = context.permute(0, 2, 1, 3).contiguous().view(batch_size, -1, self.d_model)
        
        return self.W_o(context), attention_weights


class CrossAttention(nn.Module):
    def __init__(self, d_model, num_heads, dropout=0.1):
        super().__init__()
        self.attention = MultiHeadAttention(d_model, num_heads, dropout)
        self.norm = nn.LayerNorm(d_model)
        self.dropout = nn.Dropout(dropout)
    
    def forward(self, query, key_value, mask=None):
        attended, attn_weights = self.attention(query, key_value, key_value, mask)
        return self.norm(query + self.dropout(attended)), attn_weights


class PositionalEncoding(nn.Module):
    def __init__(self, d_model, max_len=100):
        super().__init__()
        pe = torch.zeros(max_len, d_model)
        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)
        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))
        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)
        self.register_buffer('pe', pe.unsqueeze(0))
    
    def forward(self, x):
        return x + self.pe[:, :x.size(1), :]


class AttentionEnhancedDeepHedge(nn.Module):
    def __init__(self, input_dim=34, d_model=64, num_heads=4, num_layers=2, max_position=2.0, dropout=0.1):
        super().__init__()
        self.max_position = max_position
        self.d_model = d_model
        self.num_heads = num_heads
        self.num_layers = num_layers
        
        self.group_dims = {'market': 8, 'signal': 7, 'position': 5, 'minvola': 6, 'football': 8}
        
        logger.info(f"‚ö° Initializing Attention Model: d_model={d_model}, heads={num_heads}, layers={num_layers}")
        
        self.market_proj = nn.Sequential(nn.Linear(8, d_model), nn.LayerNorm(d_model), nn.ReLU())
        self.signal_proj = nn.Sequential(nn.Linear(7, d_model), nn.LayerNorm(d_model), nn.ReLU())
        self.position_proj = nn.Sequential(nn.Linear(5, d_model), nn.LayerNorm(d_model), nn.ReLU())
        self.minvola_proj = nn.Sequential(nn.Linear(6, d_model), nn.LayerNorm(d_model), nn.ReLU())
        self.football_proj = nn.Sequential(nn.Linear(8, d_model), nn.LayerNorm(d_model), nn.ReLU())
        
        self.pos_encoding = PositionalEncoding(d_model, max_len=5)
        
        self.self_attention_layers = nn.ModuleList([
            MultiHeadAttention(d_model, num_heads, dropout) for _ in range(num_layers)
        ])
        
        self.norms = nn.ModuleList([nn.LayerNorm(d_model) for _ in range(num_layers * 2)])
        
        self.ffn_layers = nn.ModuleList([
            nn.Sequential(
                nn.Linear(d_model, d_model * 4), nn.ReLU(), nn.Dropout(dropout),
                nn.Linear(d_model * 4, d_model), nn.Dropout(dropout)
            ) for _ in range(num_layers)
        ])
        
        self.market_signal_attention = CrossAttention(d_model, num_heads, dropout)
        self.position_minvola_attention = CrossAttention(d_model, num_heads, dropout)
        
        self.global_pool = nn.Sequential(
            nn.Linear(d_model * 5, d_model * 2), nn.ReLU(), nn.Dropout(dropout),
            nn.Linear(d_model * 2, d_model)
        )
        
        self.output_norm = nn.LayerNorm(d_model)
        self.output_fc = nn.Sequential(
            nn.Linear(d_model, d_model // 2), nn.ReLU(), nn.Dropout(dropout),
            nn.Linear(d_model // 2, 1), nn.Tanh()
        )
        
        self.minvola_weight = nn.Parameter(torch.tensor([0.3]))
        self.attention_weights = {}
        
        logger.info(f"   Parameters: {sum(p.numel() for p in self.parameters()):,}")
    
    def split_features(self, state_vector):
        idx = 0
        features = {}
        for name, dim in self.group_dims.items():
            features[name] = state_vector[:, idx:idx+dim]
            idx += dim
        return features
    
    def forward(self, state_vector, minvola_target):
        if state_vector.dim() == 1:
            state_vector = state_vector.unsqueeze(0)
        if minvola_target.dim() == 0:
            minvola_target = minvola_target.unsqueeze(0).unsqueeze(0)
        elif minvola_target.dim() == 1:
            minvola_target = minvola_target.unsqueeze(0)
        
        batch_size = state_vector.size(0)
        features = self.split_features(state_vector)
        
        x = torch.stack([
            self.market_proj(features['market']),
            self.signal_proj(features['signal']),
            self.position_proj(features['position']),
            self.minvola_proj(features['minvola']),
            self.football_proj(features['football'])
        ], dim=1)
        
        x = self.pos_encoding(x)
        
        for i in range(self.num_layers):
            attn_output, attn_weights = self.self_attention_layers[i](x, x, x)
            x = self.norms[i * 2](x + attn_output)
            ffn_output = self.ffn_layers[i](x)
            x = self.norms[i * 2 + 1](x + ffn_output)
            self.attention_weights[f'layer_{i}'] = attn_weights.detach()
        
        market_attended, _ = self.market_signal_attention(x[:, 0:1, :], x[:, 1:2, :])
        position_attended, _ = self.position_minvola_attention(x[:, 2:3, :], x[:, 3:4, :])
        
        x_updated = x.clone()
        x_updated[:, 0:1, :] = market_attended
        x_updated[:, 2:3, :] = position_attended
        
        aggregated = self.global_pool(x_updated.view(batch_size, -1))
        network_position = self.max_position * self.output_fc(self.output_norm(aggregated))
        
        return (
            torch.sigmoid(self.minvola_weight) * minvola_target +
            (1 - torch.sigmoid(self.minvola_weight)) * network_position
        )
    
    def forward_with_explanation(self, state_vector, minvola_target):
        position = self.forward(state_vector, minvola_target)
        
        explanation = {
            'final_position': position.item() if position.numel() == 1 else position.squeeze().tolist(),
            'minvola_target': minvola_target.item() if minvola_target.numel() == 1 else minvola_target.squeeze().tolist(),
            'minvola_weight': torch.sigmoid(self.minvola_weight).item(),
            'feature_importance': {}
        }
        
        if 'layer_1' in self.attention_weights:
            last_attn = self.attention_weights['layer_1']
            importance = last_attn.mean(dim=(0, 1, 2))
            feature_names = ['market', 'signal', 'position', 'minvola', 'football']
            for i, name in enumerate(feature_names):
                if i < len(importance):
                    explanation['feature_importance'][name] = float(importance[i])
        
        return position, explanation


# ============================================================================
# CORE MODULES (Simplified stubs)
# ============================================================================

class MinVolaModule:
    def __init__(self, max_position=2.0, min_return=0.0001):
        self.max_position = max_position
        self.min_return = min_return
        self.lookback = 100
    
    def estimate_variance(self, returns_history):
        if len(returns_history) < 10:
            return 0.01
        recent_returns = returns_history[-min(self.lookback, len(returns_history)):]
        weights = np.exp(np.linspace(-2, 0, len(recent_returns)))
        weights /= weights.sum()
        mean_return = np.average(recent_returns, weights=weights)
        return max(np.average((recent_returns - mean_return)**2, weights=weights), 1e-6)
    
    def estimate_expected_return(self, quantum_signal, horizon=5):
        signal_strength = quantum_signal.get('direction', 0.0) * quantum_signal.get('confidence', 0.0)
        return signal_strength * 0.0015 * np.sqrt(horizon / 20.0)
    
    def greedy_minvola(self, expected_return, variance, current_position=0.0):
        if abs(expected_return) < 1e-8:
            return 0.0
        if expected_return > 0:
            optimal_position = min(self.max_position, max(self.min_return / expected_return, 0.0))
        else:
            optimal_position = max(-self.max_position, min(self.min_return / expected_return, 0.0))
        return np.clip(optimal_position, -self.max_position, self.max_position)
    
    def compute_minvola_target(self, market_state, quantum_signal):
        returns = market_state.get('returns_history', np.array([]))
        variance = self.estimate_variance(returns)
        expected_return = self.estimate_expected_return(quantum_signal)
        delta_mv = self.greedy_minvola(expected_return, variance, market_state.get('current_position', 0.0))
        
        position_variance = (delta_mv ** 2) * variance
        position_return = delta_mv * expected_return
        sharpe = position_return / np.sqrt(position_variance) if position_variance > 0 else 0.0
        
        return {
            'delta_mv': delta_mv,
            'expected_return': expected_return,
            'variance': variance,
            'metrics': {
                'variance': position_variance,
                'volatility': np.sqrt(position_variance),
                'expected_return': position_return,
                'sharpe': sharpe,
                'leverage': abs(delta_mv) / self.max_position if self.max_position > 0 else 0.0
            }
        }


class TransactionCost:
    def __init__(self, epsilon=0.0005, commission=0.35, impact_lambda=0.1):
        self.epsilon = epsilon
        self.commission = commission
        self.impact_lambda = impact_lambda
    
    def compute_cost(self, trade_size, price, spread=0.03, adv=1e6):
        abs_size = abs(trade_size)
        if abs_size < 1e-6:
            return 0.0
        return (self.commission * abs_size + 0.5 * spread * abs_size +
                self.epsilon * price * abs_size +
                self.impact_lambda * price * abs_size * np.sqrt(abs_size / adv))


class PressingFatigueMonitor:
    def __init__(self, max_consecutive_losses=3, cooldown_period=20):
        self.consecutive_losses = 0
        self.pressing_cooldown = 0
        self.max_consecutive_losses = max_consecutive_losses
        self.cooldown_period = cooldown_period
        self.trade_history = deque(maxlen=100)
    
    def update(self, trade_result):
        self.trade_history.append(trade_result)
        if trade_result < 0:
            self.consecutive_losses += 1
        else:
            self.consecutive_losses = max(0, self.consecutive_losses - 1)
        if self.consecutive_losses >= self.max_consecutive_losses:
            self.pressing_cooldown = self.cooldown_period
            logger.warning("‚ö†Ô∏è  PRESSING FATIGUE: Recovery mode")
    
    def get_fatigue_factor(self):
        if self.pressing_cooldown > 0:
            self.pressing_cooldown -= 1
            return 0.5
        return 1.0


class PortfolioFormation:
    @staticmethod
    def formation_433_aggressive():
        return {'name': '4-3-3', 'max_position': 2.0, 'signal_weight': 1.4, 
                'cost_tolerance': 0.15, 'rebalance_threshold': 0.3, 'stop_loss': -0.08}
    
    @staticmethod
    def formation_442_balanced():
        return {'name': '4-4-2', 'max_position': 1.5, 'signal_weight': 1.0,
                'cost_tolerance': 0.10, 'rebalance_threshold': 0.5, 'stop_loss': -0.12}
    
    @staticmethod
    def formation_451_defensive():
        return {'name': '4-5-1', 'max_position': 0.8, 'signal_weight': 0.6,
                'cost_tolerance': 0.05, 'rebalance_threshold': 0.8, 'stop_loss': -0.15}
    
    @staticmethod
    def formation_541_ultra_defensive():
        return {'name': '5-4-1', 'max_position': 0.3, 'signal_weight': 0.3,
                'cost_tolerance': 0.02, 'rebalance_threshold': 1.0, 'stop_loss': -0.20}


class FormationManager:
    def __init__(self):
        self.current_formation = PortfolioFormation.formation_442_balanced()
        self.formation_duration = 0
        self.min_duration = 20
    
    def select_formation(self, market_state):
        vol_ratio = market_state.get('vol_ratio', 1.0)
        signal_quality = market_state.get('signal_accuracy', 0.5)
        recent_pnl = market_state.get('rolling_pnl', 0.0)
        
        if vol_ratio < 0.8 and signal_quality > 0.65 and recent_pnl > 0:
            return PortfolioFormation.formation_433_aggressive()
        elif vol_ratio > 1.2 or signal_quality < 0.50 or recent_pnl < -0.10:
            return PortfolioFormation.formation_451_defensive()
        elif vol_ratio > 1.4 or recent_pnl < -0.20:
            return PortfolioFormation.formation_541_ultra_defensive()
        else:
            return PortfolioFormation.formation_442_balanced()
    
    def update_formation(self, market_state):
        suggested_formation = self.select_formation(market_state)
        
        if suggested_formation['name'] == self.current_formation['name']:
            self.formation_duration += 1
            return self.current_formation
        
        vol_spike = market_state.get('vol_spike', False)
        flash_crash = market_state.get('flash_crash', False)
        
        if self.formation_duration >= self.min_duration or vol_spike or flash_crash:
            logger.info(f"üìä Formation switch: {self.current_formation['name']} ‚Üí {suggested_formation['name']}")
            self.current_formation = suggested_formation
            self.formation_duration = 0
        
        return self.current_formation


class FootballTacticsManager:
    def __init__(self):
        self.formation_manager = FormationManager()
        self.fatigue_monitor = PressingFatigueMonitor()
    
    def compute_control_score(self, quantum_signal, volatility, recent_accuracy, current_position, transaction_cost):
        signal_edge = quantum_signal.get('confidence', 0.5) * recent_accuracy
        vol_pressure = max(volatility / 75.0, 0.01)
        control = signal_edge / vol_pressure
        return np.clip(control, 0.0, 1.0)
    
    def compute_pressing_intensity(self, recent_win_rate, energy_level, signal_strength, volatility):
        energy = np.clip(energy_level, 0.0, 1.0)
        momentum = np.clip((recent_win_rate - 0.5) * 2, -1.0, 1.0)
        signal_quality = np.clip(signal_strength, 0.0, 1.0)
        vol_penalty = 1.0 / (1.0 + max(volatility / 75.0 - 1.0, 0.0))
        
        intensity = energy * 0.3 + momentum * 0.3 + signal_quality * 0.3 + vol_penalty * 0.1
        return np.clip(intensity, 0.0, 1.0)
    
    def compute_features(self, market_state, quantum_signal, current_position):
        formation = self.formation_manager.update_formation(market_state)
        
        control_score = self.compute_control_score(
            quantum_signal, market_state.get('volatility', 75.0),
            market_state.get('signal_accuracy', 0.5), current_position,
            market_state.get('transaction_cost', 0.0)
        )
        
        pressing_intensity = self.compute_pressing_intensity(
            market_state.get('win_rate', 0.5), market_state.get('energy_level', 1.0),
            quantum_signal.get('confidence', 0.5), market_state.get('volatility', 75.0)
        )
        
        fatigue_factor = self.fatigue_monitor.get_fatigue_factor()
        
        formation_map = {'4-3-3': 0.0, '4-4-2': 0.33, '4-5-1': 0.66, '5-4-1': 1.0}
        formation_encoding = formation_map.get(formation['name'], 0.33)
        
        return {
            'control_score': control_score,
            'pressing_intensity': pressing_intensity,
            'fatigue_factor': fatigue_factor,
            'formation_encoding': formation_encoding,
            'formation_max_position': formation['max_position'] / 2.0,
            'formation_signal_weight': formation['signal_weight'],
            'formation_cost_tolerance': formation['cost_tolerance'],
            'formation_rebalance_threshold': formation['rebalance_threshold']
        }


class StateBuilder:
    def __init__(self):
        self.minvola_module = MinVolaModule()
        self.football_manager = FootballTacticsManager()
    
    def build_state(self, market_data, quantum_signal, current_position, entry_price=None):
        if entry_price is None:
            entry_price = market_data.get('price', 1500.0)
        
        price = market_data.get('price', 1500.0)
        returns = market_data.get('returns_history', np.array([]))
        
        if isinstance(returns, list):
            returns = np.array(returns)
        
        # Market Features (8 dims)
        price_lag1 = market_data.get('price_lag1', price)
        price_lag5 = market_data.get('price_lag5', price)
        price_lag20 = market_data.get('price_lag20', price)
        
        log_return_1 = np.log(price / price_lag1) if price_lag1 > 0 else 0.0
        log_return_5 = np.log(price / price_lag5) if price_lag5 > 0 else 0.0
        log_return_20 = np.log(price / price_lag20) if price_lag20 > 0 else 0.0
        
        if len(returns) >= 20:
            momentum_20 = float(np.mean(returns[-20:]))
            realized_vol_20 = float(np.std(returns[-20:]) * np.sqrt(252 * 24 * 12))
        else:
            momentum_20 = 0.0
            realized_vol_20 = 75.0
        
        vol_ratio = realized_vol_20 / 75.0
        spread = market_data.get('spread', 0.03)
        rel_spread = spread / price if price > 0 else 0.0
        
        market_features = np.array([
            log_return_1, log_return_5, log_return_20, momentum_20,
            realized_vol_20, vol_ratio, spread, rel_spread
        ], dtype=np.float32)
        
        # Signal Features (7 dims)
        signal_direction = quantum_signal.get('direction', 0.0)
        signal_confidence = quantum_signal.get('confidence', 0.0)
        signal_net = signal_direction * signal_confidence
        
        signal_features = np.array([
            signal_direction, signal_confidence, signal_net,
            quantum_signal.get('signal_ma5', signal_net),
            quantum_signal.get('accuracy', 0.5),
            quantum_signal.get('horizon', 5.0) / 100.0,
            quantum_signal.get('age', 0.0) / 100.0
        ], dtype=np.float32)
        
        # Position Features (5 dims)
        bars_since_entry = market_data.get('bars_since_entry', 0)
        unrealized_pnl = market_data.get('current_pnl', 0.0)
        
        position_features = np.array([
            current_position / 2.0,
            unrealized_pnl / 1000.0,
            bars_since_entry / 100.0,
            bars_since_entry / max(quantum_signal.get('horizon', 20), 1),
            (price - entry_price) / entry_price if entry_price > 0 else 0.0
        ], dtype=np.float32)
        
        # MinVola Features (6 dims)
        market_state_for_minvola = {
            'returns_history': returns,
            'current_position': current_position,
            'volatility': realized_vol_20
        }
        
        minvola_output = self.minvola_module.compute_minvola_target(market_state_for_minvola, quantum_signal)
        
        minvola_features = np.array([
            minvola_output['delta_mv'] / 2.0,
            minvola_output['expected_return'],
            minvola_output['variance'],
            minvola_output['metrics']['sharpe'],
            minvola_output['metrics']['leverage'],
            (current_position - minvola_output['delta_mv']) / 2.0
        ], dtype=np.float32)
        
        # Football Features (8 dims)
        market_state_for_football = {
            'volatility': realized_vol_20,
            'signal_accuracy': quantum_signal.get('accuracy', 0.5),
            'win_rate': market_data.get('win_rate', 0.5),
            'energy_level': market_data.get('energy_level', 1.0),
            'transaction_cost': market_data.get('transaction_cost', 0.0),
            'vol_ratio': vol_ratio,
            'rolling_pnl': unrealized_pnl,
            'vol_spike': market_data.get('vol_spike', False),
            'flash_crash': market_data.get('flash_crash', False)
        }
        
        football_features_dict = self.football_manager.compute_features(
            market_state_for_football, quantum_signal, current_position
        )
        
        football_features = np.array([
            football_features_dict['control_score'],
            football_features_dict['pressing_intensity'],
            football_features_dict['fatigue_factor'],
            football_features_dict['formation_encoding'],
            football_features_dict['formation_max_position'],
            football_features_dict['formation_signal_weight'],
            football_features_dict['formation_cost_tolerance'],
            football_features_dict['formation_rebalance_threshold']
        ], dtype=np.float32)
        
        state_vector = np.concatenate([
            market_features, signal_features, position_features,
            minvola_features, football_features
        ])
        
        return {
            'market': market_features,
            'signal': signal_features,
            'position': position_features,
            'minvola': minvola_features,
            'football': football_features,
            'vector': state_vector,
            'minvola_output': minvola_output
        }


class PositionBuffer:
    def __init__(self, buffer_size=5):
        self.buffer = deque(maxlen=buffer_size)
        self.last_confirmed_position = 0.0
    
    def add_signal(self, signal_action, signal_confidence, model_position):
        direction_map = {'BUY': 1.0, 'SELL': -1.0, 'HOLD': 0.0}
        numeric_direction = direction_map.get(signal_action, 0.0)
        
        self.buffer.append({
            'action': signal_action,
            'direction': numeric_direction,
            'confidence': signal_confidence,
            'model_position': model_position,
            'timestamp': time.time()
        })
    
    def get_consensus_action(self):
        if len(self.buffer) == 0:
            return {'action': 'HOLD', 'volume': 0.0, 'confidence': 0.0}
        
        buy_weight = sum(s['confidence'] for s in self.buffer if s['action'] == 'BUY')
        sell_weight = sum(s['confidence'] for s in self.buffer if s['action'] == 'SELL')
        hold_weight = sum(s['confidence'] for s in self.buffer if s['action'] == 'HOLD')
        
        total_weight = buy_weight + sell_weight + hold_weight
        
        if total_weight > 0:
            buy_pct = buy_weight / total_weight
            sell_pct = sell_weight / total_weight
            hold_pct = hold_weight / total_weight
        else:
            buy_pct = sell_pct = hold_pct = 0.33
        
        latest_model_position = self.buffer[-1]['model_position']
        avg_confidence = sum(s['confidence'] for s in self.buffer) / len(self.buffer)
        
        if buy_pct > 0.4 and buy_pct > sell_pct:
            action = 'BUY'
            volume = abs(latest_model_position)
        elif sell_pct > 0.4 and sell_pct > buy_pct:
            action = 'SELL'
            volume = abs(latest_model_position)
        else:
            action = 'HOLD'
            volume = 0.0
        
        return {
            'action': action, 'volume': volume, 'confidence': avg_confidence,
            'buy_weight': buy_pct, 'sell_weight': sell_pct, 'hold_weight': hold_pct,
            'model_position': latest_model_position
        }
    
    def confirm_position(self, position):
        self.last_confirmed_position = position


# ============================================================================
# RATE LIMITER FOR CLOSE ORDERS
# ============================================================================

class OrderRateLimiter:
    def __init__(self, max_orders_per_minute=10):
        self.max_orders = max_orders_per_minute
        self.order_times = deque(maxlen=max_orders_per_minute)
        self.lock = asyncio.Lock()
    
    async def can_send(self):
        async with self.lock:
            now = time.time()
            # Remove orders older than 60 seconds
            while self.order_times and self.order_times[0] < now - 60:
                self.order_times.popleft()
            
            if len(self.order_times) < self.max_orders:
                self.order_times.append(now)
                return True
            return False
    
    async def wait_until_can_send(self):
        while not await self.can_send():
            await asyncio.sleep(1)


# ============================================================================
# MAIN TRADING SYSTEM
# ============================================================================

class FootballInspiredTradingSystem:
    def __init__(self, max_position=2.0, min_lot_size=0.001, lot_size_step=0.001,
                 d_model=64, num_heads=4, num_layers=2):
        print("üöÄ Initializing DeepHedge PlayMaker v2.2-FINAL...")
        sys.stdout.flush()

        # Model
        try:
            self.model = AttentionEnhancedDeepHedge(
                input_dim=34, d_model=d_model, num_heads=num_heads,
                num_layers=num_layers, max_position=max_position, dropout=0.1
            )
        except Exception as e:
            logger.warning(f"Model initialization deferred: {e}")
            self.model = None

        # Core components
        self.state_builder = StateBuilder()
        self.transaction_cost_model = TransactionCost()
        self.formation_manager = FormationManager()
        self.fatigue_monitor = PressingFatigueMonitor()
        self.position_buffer = PositionBuffer(buffer_size=3)
        
        # ‚úÖ Exit optimizer
        self.exit_optimizer = PortfolioExitOptimizer(
            min_exit_size=min_lot_size,
            max_exit_pct=0.5
        )
        
        # ‚úÖ Rate limiters
        self.order_rate_limiter = OrderRateLimiter(max_orders_per_minute=10)
        self.close_order_rate_limiter = OrderRateLimiter(max_orders_per_minute=5)

        # Position sizing
        self.max_position = max_position
        self.min_lot_size = min_lot_size
        self.lot_size_step = lot_size_step

        # Ably
        self.ably_key = f"{ABLY_KEY_NAME}:{ABLY_KEY_SECRET}"
        self.ably_realtime = None
        self.signal_channel = None
        self.price_channel = None
        self.order_channel = None

        # State tracking
        self.current_position = 0.0
        self.entry_price = 1500.0
        self.current_pnl = 0.0
        self.trade_history = deque(maxlen=100)
        self.price_history = deque(maxlen=200)
        self.returns_history = deque(maxlen=200)
        self.signal_history = deque(maxlen=100)

        # Market data
        self.latest_price = 1500.0
        self.latest_spread = 0.03
        self.latest_signal = {'direction': 0.0, 'confidence': 0.0}

        # Performance
        self.total_trades = 0
        self.winning_trades = 0

        # Connection status
        self.connected = False
        self.last_signal_time = None
        self.last_price_time = None

        # ‚úÖ Thread-safe position cache
        self.open_positions_cache = []
        self.last_positions_update = 0
        self.position_cache_timeout = 30
        self.position_cache_lock = asyncio.Lock()

        logger.info("‚úÖ FootballInspiredTradingSystem v2.2-FINAL initialized")
        logger.info(f"   Max Position: ¬±{self.max_position} lots")
        logger.info(f"   Exit Optimizer: ACTIVE with thread-safe cache")
        print("‚úÖ Initialization complete")
        sys.stdout.flush()
    
    def normalize_volume(self, volume):
        volume = round(volume / self.lot_size_step) * self.lot_size_step
        if abs(volume) < self.min_lot_size:
            return 0.0
        volume = np.clip(volume, -self.max_position, self.max_position)
        return round(volume, 3)
    
    def validate_position_data(self, position):
        """‚úÖ Validate position dict has required fields with correct types"""
        required_fields = {
            'ticket': (int, float),  # Can be int or float ticket ID
            'type': (str,),
            'volume': (int, float),
            'profit': (int, float),
            'price_open': (int, float),
            'time_open': (int, float)
        }
        
        for field, types in required_fields.items():
            if field not in position:
                return False, f"Missing field: {field}"
            if not isinstance(position[field], types):
                return False, f"Invalid type for {field}: expected {types}, got {type(position[field])}"
        
        # Additional checks
        if position['type'] not in ['BUY', 'SELL']:
            return False, f"Invalid position type: {position['type']}"
        if position['volume'] <= 0:
            return False, f"Invalid volume: {position['volume']}"
        
        return True, "Valid"
    
    async def initialize_ably(self):
        if not ABLY_AVAILABLE:
            logger.error("‚ùå Ably not available")
            return False

        try:
            print("üîå Connecting to Ably...")
            sys.stdout.flush()

            self.ably_realtime = AblyRealtime(self.ably_key)

            connection_timeout = 10
            start_time = time.time()

            while self.ably_realtime.connection.state != 'connected':
                if time.time() - start_time > connection_timeout:
                    raise TimeoutError("Ably connection timeout")
                await asyncio.sleep(0.5)
                print(".", end="")
                sys.stdout.flush()

            print("\n‚úÖ Ably connected!")
            sys.stdout.flush()

            self.signal_channel = self.ably_realtime.channels.get(ABLY_SIGNAL_CHANNEL)
            self.price_channel = self.ably_realtime.channels.get(ABLY_PRICE_SPREAD_POSITIONINFO_CHANNEL)
            self.order_channel = self.ably_realtime.channels.get(ABLY_MT5_ORDERS_CHANNEL)

            await self.signal_channel.subscribe(self.on_signal_received)
            await self.price_channel.subscribe(self.on_price_received)

            self.connected = True

            logger.info("‚úÖ Ably connected successfully")
            print("‚úÖ All channels subscribed")
            sys.stdout.flush()

            return True

        except Exception as e:
            logger.error(f"‚ùå Ably initialization failed: {e}")
            traceback.print_exc()
            return False
    
    async def on_signal_received(self, message):
        try:
            data = message.data if isinstance(message.data, dict) else json.loads(message.data)

            final_action = data.get('final_action', 'HOLD')
            direction_map = {'BUY': 1.0, 'SELL': -1.0, 'HOLD': 0.0}
            numeric_direction = direction_map.get(final_action, 0.0)
            confidence = float(data.get('confidence', 0.0))

            self.latest_signal = {
                'direction': numeric_direction,
                'confidence': confidence,
                'action': final_action,
                'price': float(data.get('price', self.latest_price)),
                'agent_count': data.get('agent_count', 0),
                'signal_keys': data.get('signal_keys', []),
                'horizon': 20,
                'timestamp': data.get('timestamp', datetime.now(timezone.utc).isoformat())
            }

            self.signal_history.append(self.latest_signal)
            self.last_signal_time = time.time()

            logger.info(f"üì° Signal: {final_action} | DIR={numeric_direction:+.2f} | CONF={confidence:.2f}")

            await self.make_trading_decision()

        except Exception as e:
            logger.error(f"‚ùå Error processing signal: {e}")
            traceback.print_exc()
    
    async def on_price_received(self, message):
        """‚úÖ Enhanced with validation and thread-safe cache"""
        try:
            data = message.data if isinstance(message.data, dict) else json.loads(message.data)

            self.latest_price = float(data.get('price', self.latest_price))
            self.latest_spread = float(data.get('spread', 0.03))

            if 'current_position' in data:
                old_position = self.current_position
                self.current_position = float(data.get('current_position', 0.0))
                self.position_buffer.confirm_position(self.current_position)

                if abs(old_position - self.current_position) > 0.001:
                    logger.info(f"üìç Position updated: {old_position:.3f} ‚Üí {self.current_position:.3f}")

            if 'current_pnl' in data:
                self.current_pnl = float(data.get('current_pnl', 0.0))

            self.price_history.append(self.latest_price)
            self.last_price_time = time.time()

            if len(self.price_history) >= 2:
                ret = (self.price_history[-1] - self.price_history[-2]) / self.price_history[-2]
                self.returns_history.append(ret)

            # ‚úÖ Thread-safe position cache update with validation
            if 'positions' in data:
                positions_data = data['positions']

                if isinstance(positions_data, list):
                    valid_positions = []
                    for pos in positions_data:
                        is_valid, msg = self.validate_position_data(pos)
                        if is_valid:
                            valid_positions.append(pos)
                        else:
                            logger.warning(f"‚ö†Ô∏è Invalid position: {msg} | Data: {pos}")

                    if valid_positions:
                        async with self.position_cache_lock:
                            self.open_positions_cache = valid_positions
                            self.last_positions_update = time.time()
                        logger.debug(f"üì¶ Position cache updated: {len(valid_positions)} valid positions")
                    else:
                        logger.warning("‚ö†Ô∏è No valid positions in data")
                else:
                    logger.warning(f"‚ö†Ô∏è Positions data is not a list: {type(positions_data)}")

        except Exception as e:
            logger.error(f"‚ùå Error processing price/position data: {e}")
            traceback.print_exc()
    
    async def make_trading_decision(self):
        try:
            if len(self.returns_history) >= 20:
                recent_returns = list(self.returns_history)[-20:]
                volatility = float(np.std(recent_returns) * np.sqrt(252 * 24 * 12))
            else:
                volatility = 75.0

            market_data = {
                'price': self.latest_price,
                'price_lag1': self.price_history[-2] if len(self.price_history) >= 2 else self.latest_price,
                'price_lag5': self.price_history[-6] if len(self.price_history) >= 6 else self.latest_price,
                'price_lag20': self.price_history[-21] if len(self.price_history) >= 21 else self.latest_price,
                'returns_history': np.array(list(self.returns_history), dtype=np.float32),
                'spread': self.latest_spread,
                'bars_since_entry': len(self.trade_history),
                'win_rate': self.winning_trades / max(self.total_trades, 1),
                'energy_level': 1.0 - abs(self.current_pnl / 10000.0),
                'rolling_pnl': self.current_pnl,
                'current_pnl': self.current_pnl,
                'volatility': volatility
            }

            state = self.state_builder.build_state(
                market_data, self.latest_signal, self.current_position, self.entry_price
            )

            # ‚úÖ FIXED: Correct dict access
            minvola_target = state['minvola_output']['delta_mv']

            state_tensor = torch.FloatTensor(state['vector']).unsqueeze(0)
            minvola_tensor = torch.FloatTensor([[minvola_target]])

            base_position = 0.0
            explanation = {}
            
            if self.model is not None:
                self.model.eval()
                with torch.no_grad():
                    try:
                        # ‚úÖ FIXED: Compatible with forward_with_explanation
                        base_pos_out, explanation = self.model.forward_with_explanation(
                            state_tensor, minvola_tensor
                        )
                        base_position = float(base_pos_out.item() if base_pos_out.numel() == 1 else base_pos_out.squeeze().mean().item())
                    except AttributeError:
                        # Fallback: model.forward expects (state_vector, minvola_target)
                        base_pos_out = self.model(state_tensor, minvola_tensor)
                        base_position = float(base_pos_out.item() if base_pos_out.numel() == 1 else base_pos_out.squeeze().mean().item())

            if self.total_trades % 10 == 0 and 'feature_importance' in explanation:
                logger.info("üéØ Attention Insights:")
                for feat, imp in explanation['feature_importance'].items():
                    logger.info(f"   {feat:12s}: {imp:.3f}")

            formation = self.formation_manager.current_formation
            base_position = np.clip(base_position, -formation['max_position'], formation['max_position'])

            self.position_buffer.add_signal(
                signal_action=self.latest_signal.get('action', 'HOLD'),
                signal_confidence=self.latest_signal['confidence'],
                model_position=base_position
            )

            consensus = self.position_buffer.get_consensus_action()

            fatigue_factor = self.fatigue_monitor.get_fatigue_factor()
            final_volume = consensus['volume'] * fatigue_factor
            final_volume = self.normalize_volume(final_volume)

            if final_volume >= self.min_lot_size and consensus['action'] != 'HOLD':
                await self.send_order(consensus['action'], final_volume)

                logger.info(
                    f"üìä Decision: {consensus['action']} {final_volume:.3f} lots | "
                    f"Consensus: BUY={consensus['buy_weight']:.1%} SELL={consensus['sell_weight']:.1%}"
                )
            else:
                logger.info(f"‚è∏Ô∏è Holding | Consensus: {consensus['action']}")

        except Exception as e:
            logger.error(f"‚ùå Error in trading decision: {e}")
            traceback.print_exc()
    
    async def send_order(self, action, volume):
        try:
            if action not in ['BUY', 'SELL']:
                return

            volume = self.normalize_volume(volume)
            if volume < self.min_lot_size:
                return
            
            # ‚úÖ Rate limit check
            await self.order_rate_limiter.wait_until_can_send()

            order_data = {
                'action': action,
                'volume': volume,
                'symbol': 'Volatility 75 Index',
                'type': 'MARKET',
                'timestamp': datetime.now(timezone.utc).isoformat(),
                'current_position': self.current_position,
                'signal_direction': self.latest_signal['direction'],
                'signal_confidence': self.latest_signal['confidence'],
                'reason': 'DeepHedge PlayMaker v2.2-FINAL'
            }

            await self.order_channel.publish('order', order_data)
            self.total_trades += 1

            logger.info(f"üì§ Order sent: {action} {volume:.3f} lots")
            print(f"üì§ ORDER SENT: {action} {volume:.3f} lots")
            sys.stdout.flush()

        except Exception as e:
            logger.error(f"‚ùå Error sending order: {e}")
            traceback.print_exc()
    
    async def send_close_order(self, close_order):
        """‚úÖ Send CLOSE order with rate limiting"""
        try:
            # ‚úÖ Rate limit for close orders
            await self.close_order_rate_limiter.wait_until_can_send()
            
            order_data = {
                'action': 'CLOSE',
                'ticket': close_order['ticket'],
                'volume': close_order['volume'],
                'symbol': 'Volatility 75 Index',
                'reason': close_order['reason'],
                'timestamp': datetime.now(timezone.utc).isoformat(),
                'exit_score': close_order.get('exit_score', 0.0)
            }

            await self.order_channel.publish('close_order', order_data)

            logger.info(f"üîí Close order sent: Ticket {close_order['ticket']}, "
                       f"Volume {close_order['volume']:.3f}")
            logger.info(f"   Reason: {close_order['reason']}")

            print(f"üîí CLOSE ORDER: Ticket {close_order['ticket']} | {close_order['volume']:.3f} lots")
            sys.stdout.flush()

        except Exception as e:
            logger.error(f"‚ùå Error sending close order: {e}")
            traceback.print_exc()
    
    async def evaluate_portfolio_exits(self):
        """‚úÖ Thread-safe exit evaluation"""
        logger.info("üîç Portfolio Exit Evaluator started")

        while True:
            try:
                await asyncio.sleep(300)  # Every 5 minutes

                # ‚úÖ Thread-safe cache access
                async with self.position_cache_lock:
                    positions_snapshot = self.open_positions_cache.copy()
                    cache_age = time.time() - self.last_positions_update

                if not positions_snapshot:
                    logger.info("‚ÑπÔ∏è No open positions to evaluate")
                    continue

                if cache_age > self.position_cache_timeout:
                    logger.warning(f"‚ö†Ô∏è Position data is stale ({cache_age:.0f}s old), skipping exit evaluation")
                    continue

                # Market data
                if len(self.returns_history) >= 20:
                    recent_returns = list(self.returns_history)[-20:]
                    realized_vol = float(np.std(recent_returns) * np.sqrt(252 * 24 * 12))
                else:
                    realized_vol = 75.0

                market_data = {
                    'price': self.latest_price,
                    'realized_vol': realized_vol,
                    'spread': self.latest_spread,
                    'vol_ratio': realized_vol / 75.0
                }

                logger.info(f"üìä Evaluating {len(positions_snapshot)} positions for exit...")

                exit_orders = self.exit_optimizer.evaluate_exits(
                    positions_snapshot,
                    market_data,
                    self.latest_signal
                )

                if exit_orders:
                    logger.info(f"üéØ Generated {len(exit_orders)} exit orders")
                    for order in exit_orders:
                        await self.send_close_order(order)
                        await asyncio.sleep(1)
                else:
                    logger.info("‚úÖ No positions require closing at this time")

            except Exception as e:
                logger.error(f"‚ùå Exit evaluation error: {e}")
                traceback.print_exc()
                await asyncio.sleep(60)
    
    def load_model(self, path):
        try:
            if self.model is None:
                logger.warning("No model instance present ‚Äì cannot load state_dict")
                return
            self.model.load_state_dict(torch.load(path))
            self.model.eval()
            logger.info(f"‚úÖ Model loaded from {path}")
        except Exception as e:
            logger.error(f"‚ùå Error loading model: {e}")

    def save_model(self, path):
        try:
            if self.model is None:
                logger.warning("No model instance present ‚Äì nothing to save")
                return
            torch.save(self.model.state_dict(), path)
            logger.info(f"‚úÖ Model saved to {path}")
        except Exception as e:
            logger.error(f"‚ùå Error saving model: {e}")
    
    async def heartbeat_monitor(self):
        while True:
            await asyncio.sleep(30)

            current_time = time.time()
            status_msg = "üíì Heartbeat: "

            if self.connected:
                status_msg += "CONNECTED | "
            else:
                status_msg += "DISCONNECTED | "

            if self.last_signal_time:
                signal_age = current_time - self.last_signal_time
                status_msg += f"Signal: {signal_age:.0f}s ago | "
            else:
                status_msg += "No signals | "

            if self.last_price_time:
                price_age = current_time - self.last_price_time
                status_msg += f"Price: {price_age:.0f}s ago | "
            else:
                status_msg += "No prices | "

            async with self.position_cache_lock:
                num_positions = len(self.open_positions_cache)
            
            status_msg += f"Positions: {num_positions}"

            logger.info(status_msg)
            print(status_msg)
            sys.stdout.flush()


# ============================================================================
# MAIN FUNCTION
# ============================================================================

async def main():
    print("=" * 80)
    print("üöÄ DeepHedge PlayMaker v2.2-FINAL - Starting...")
    print("=" * 80)
    sys.stdout.flush()

    logger.info("üöÄ DeepHedge PlayMaker v2.2-FINAL Starting...")

    system = FootballInspiredTradingSystem(
        max_position=2.0,
        min_lot_size=0.001,
        lot_size_step=0.001,
        d_model=64,
        num_heads=4,
        num_layers=2
    )

    print("\nüîå Attempting Ably connection...")
    sys.stdout.flush()

    connected = await system.initialize_ably()

    if not connected:
        logger.error("‚ùå Failed to connect to Ably. Exiting.")
        return

    print("\n‚úÖ System ready. Features:")
    print("   üéØ Multi-Head Attention: ACTIVE")
    print("   üîí Portfolio Exit Optimizer: ACTIVE")
    print("   üìä Real-time Risk Management: ACTIVE")
    print("   ‚úÖ Thread-safe position cache: ACTIVE")
    print("   ‚úÖ Rate limiting (orders & closes): ACTIVE")
    print("   ‚úÖ Position data validation: ACTIVE")
    print("\n   Exit Evaluation: Every 5 minutes")
    print("   Exit Strategies: Risk, Return, Time, Regime, Reversal")
    print("\nPress Ctrl+C to stop\n")
    sys.stdout.flush()

    try:
        heartbeat_task = asyncio.create_task(system.heartbeat_monitor())
        exit_evaluator_task = asyncio.create_task(system.evaluate_portfolio_exits())

        while True:
            await asyncio.sleep(1)

    except KeyboardInterrupt:
        print("\nüõë Shutting down...")
        sys.stdout.flush()
        logger.info("\nüõë Shutting down...")
    finally:
        if system.ably_realtime:
            try:
                system.ably_realtime.close()
            except Exception:
                pass
        logger.info("üëã System stopped")
        print("üëã System stopped")
        sys.stdout.flush()


if __name__ == "__main__":
    try:
        import nest_asyncio
        nest_asyncio.apply()
        print("‚úÖ nest_asyncio applied")
        sys.stdout.flush()
    except ImportError:
        print("‚ö†Ô∏è Install nest_asyncio for better compatibility")
        sys.stdout.flush()

    print("\n" + "=" * 80)
    print("‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó")
    print("‚ïë         DEEPHEDGE PLAYMAKER v2.2-FINAL - PRODUCTION READY                   ‚ïë")
    print("‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù")
    print("\n   üîß Fixes Applied:")
    print("   ‚úÖ Fixed minvola_output dict access (was .get(), now direct [])")
    print("   ‚úÖ Fixed model forward compatibility")
    print("   ‚úÖ Added thread-safe position cache with asyncio.Lock")
    print("   ‚úÖ Enhanced position validation with type checking")
    print("   ‚úÖ Added rate limiting for both orders and closes")
    print("   ‚úÖ Consistent dict access patterns (.get() with defaults)")
    print("   ‚úÖ Better error handling throughout")
    print("   ‚úÖ Protected against division by zero")
    print("=" * 80 + "\n")
    sys.stdout.flush()

    try:
        asyncio.run(main())
    except Exception as e:
        print(f"\n‚ùå FATAL ERROR: {e}")
        traceback.print_exc()
        sys.stdout.flush()
        
#+263780563561  ENG Karl Muzunze Masvingo Zimbabwe